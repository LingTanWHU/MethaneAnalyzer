{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "206464cd",
   "metadata": {},
   "source": [
    "## 1. 必要依赖\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "35eb8d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "from scipy import stats\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# 设置中文字体\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "def load_picarro_data(start_date, end_date, timezone):\n",
    "    \"\"\"加载 Picarro 数据\"\"\"\n",
    "    data_path = r'Y:\\公共空间\\Data 数据 结果\\监测仪数据\\DataLog_User'\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # 遍历时间范围内的日期\n",
    "    current_date = start_date.date()\n",
    "    end_date_obj = end_date.date()\n",
    "    \n",
    "    while current_date <= end_date_obj:\n",
    "        year_folder = str(current_date.year).zfill(4)\n",
    "        month_folder = str(current_date.month).zfill(2)\n",
    "        day_folder = str(current_date.day).zfill(2)\n",
    "        \n",
    "        day_path = os.path.join(data_path, year_folder, month_folder, day_folder)\n",
    "        \n",
    "        if os.path.exists(day_path):\n",
    "            dat_files = glob.glob(os.path.join(day_path, \"*.dat\"))\n",
    "            \n",
    "            for dat_file in dat_files:\n",
    "                df = load_single_picarro_file(dat_file)\n",
    "                if df is not None and not df.empty:\n",
    "                    all_data.append(df)\n",
    "        \n",
    "        current_date += timedelta(days=1)\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        combined_df['DATETIME_DISPLAY'] = combined_df['DATETIME'].dt.tz_convert(timezone)\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"警告: 没有找到 Picarro 数据\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_pico_data(start_date, end_date, timezone):\n",
    "    \"\"\"加载 Pico 数据\"\"\"\n",
    "    data_path = r'Y:\\公共空间\\Data 数据 结果\\监测仪数据\\MIRA_Data'\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    # 查找匹配的 .txt 文件\n",
    "    all_txt_files = glob.glob(os.path.join(data_path, \"*.txt\"))\n",
    "    \n",
    "    for txt_file in all_txt_files:\n",
    "        filename = os.path.basename(txt_file)\n",
    "        # 排除不需要的文件\n",
    "        if ('Eng.txt' in filename or \n",
    "            'spectralite.txt' in filename or \n",
    "            'config.txt' in filename):\n",
    "            continue\n",
    "        \n",
    "        # 检查文件名是否符合 Pico 数据格式\n",
    "        if filename.startswith('Pico') and filename.endswith('.txt'):\n",
    "            try:\n",
    "                name_part = filename.replace('Pico', '').replace('.txt', '')\n",
    "                if '_' in name_part:\n",
    "                    date_part = name_part.split('_')[1]  # 251106\n",
    "                    year = int('20' + date_part[:2])\n",
    "                    month = int(date_part[2:4])\n",
    "                    day = int(date_part[4:6])\n",
    "                    \n",
    "                    file_date = datetime(year, month, day).date()\n",
    "                    \n",
    "                    # 检查日期是否在范围内\n",
    "                    if start_date.date() <= file_date <= end_date.date():\n",
    "                        df = load_single_pico_file(txt_file)\n",
    "                        if df is not None and not df.empty:\n",
    "                            all_data.append(df)\n",
    "            except:\n",
    "                continue\n",
    "    \n",
    "    if all_data:\n",
    "        combined_df = pd.concat(all_data, ignore_index=True)\n",
    "        combined_df['DATETIME_DISPLAY'] = combined_df['DATETIME'].dt.tz_convert(timezone)\n",
    "        return combined_df\n",
    "    else:\n",
    "        print(\"警告: 没有找到 Pico 数据\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_single_picarro_file(file_path):\n",
    "    \"\"\"加载单个 Picarro .dat 文件\"\"\"\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "            lines = f.readlines()\n",
    "        \n",
    "        header_line = None\n",
    "        data_start = 0\n",
    "        \n",
    "        for i, line in enumerate(lines):\n",
    "            if line.strip().startswith('DATE'):\n",
    "                header_line = line.strip()\n",
    "                data_start = i + 1\n",
    "                break\n",
    "        \n",
    "        if header_line is None:\n",
    "            return None\n",
    "        \n",
    "        headers = [h.strip() for h in header_line.split()]\n",
    "        data_lines = []\n",
    "        \n",
    "        for line in lines[data_start:]:\n",
    "            line = line.strip()\n",
    "            if line:\n",
    "                parts = line.split()\n",
    "                if len(parts) >= len(headers):\n",
    "                    data_lines.append(parts[:len(headers)])\n",
    "        \n",
    "        if not data_lines:\n",
    "            return None\n",
    "        \n",
    "        df = pd.DataFrame(data_lines, columns=headers)\n",
    "        \n",
    "        # 转换数值列\n",
    "        for col in ['CO2_dry', 'CH4_dry', 'H2O', 'CO2', 'CH4']:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        # 转换日期时间\n",
    "        if 'DATE' in df.columns and 'TIME' in df.columns:\n",
    "            df['DATETIME'] = pd.to_datetime(\n",
    "                df['DATE'] + ' ' + df['TIME'].str.split('.').str[0], \n",
    "                format='%Y-%m-%d %H:%M:%S', \n",
    "                errors='coerce'\n",
    "            )\n",
    "            df['DATETIME'] = df['DATETIME'].dt.tz_localize('UTC')\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def load_single_pico_file(file_path):\n",
    "    \"\"\"加载单个 Pico .txt 文件\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        \n",
    "        # 重命名列\n",
    "        column_mapping = {\n",
    "            'Time Stamp': 'DATETIME',\n",
    "            'CH4 (ppm)': 'CH4',\n",
    "            'C2H6 (ppb)': 'C2H6',\n",
    "            'H2O (ppm)': 'H2O',\n",
    "            'Tgas(degC)': 'Tgas'\n",
    "        }\n",
    "        \n",
    "        for old_col, new_col in column_mapping.items():\n",
    "            if old_col in df.columns:\n",
    "                df = df.rename(columns={old_col: new_col})\n",
    "        \n",
    "        # 转换数值列\n",
    "        for col in ['CH4', 'C2H6', 'H2O', 'Tgas']:\n",
    "            if col in df.columns:\n",
    "                df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "        \n",
    "        # 转换日期时间\n",
    "        if 'DATETIME' in df.columns:\n",
    "            df['DATETIME'] = pd.to_datetime(df['DATETIME'], format='%m/%d/%Y %H:%M:%S.%f', errors='coerce')\n",
    "            df['DATETIME'] = df['DATETIME'].dt.tz_localize('Asia/Shanghai')\n",
    "            df['DATETIME'] = df['DATETIME'].dt.tz_convert('UTC')\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        return None\n",
    "\n",
    "def resample_data(df, time_window, method='median', max_cv=0.10):\n",
    "    \"\"\"对数据进行重采样，同时计算均值/中位数和标准差，并过滤高变异点\"\"\"\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # 选择需要的列\n",
    "    cols_to_aggregate = [col for col in ['CH4_dry', 'CH4', 'H2O'] if col in df.columns]\n",
    "    \n",
    "    if not cols_to_aggregate:\n",
    "        return pd.DataFrame(), pd.DataFrame()\n",
    "    \n",
    "    # 按时间窗口重采样\n",
    "    grouped = df.set_index('DATETIME')[cols_to_aggregate].resample(time_window)\n",
    "    \n",
    "    # 计算中心值（均值或中位数）\n",
    "    if method == 'mean':\n",
    "        center_values = grouped.mean()\n",
    "    else:  # median\n",
    "        center_values = grouped.median()\n",
    "    \n",
    "    # 计算标准差\n",
    "    std_values = grouped.std()\n",
    "    \n",
    "    # 计算变异系数 (CV = std / mean) 并过滤高变异点\n",
    "    if method == 'mean':\n",
    "        # 使用均值计算变异系数\n",
    "        cv_values = std_values / center_values\n",
    "    else:\n",
    "        # 对于中位数，使用标准化四分位距或类似的变异系数\n",
    "        # 这里我们仍使用 std / median 作为变异系数的近似\n",
    "        cv_values = std_values / center_values\n",
    "    \n",
    "    # 创建掩码：变异系数小于等于最大允许值，且标准差和中心值都不为NaN\n",
    "    valid_mask = (cv_values <= max_cv) & (std_values.notna()) & (center_values.notna())\n",
    "    \n",
    "    # 应用掩码，只保留低变异点\n",
    "    center_values = center_values[valid_mask].dropna(axis=1, how='all')\n",
    "    std_values = std_values[valid_mask].dropna(axis=1, how='all')\n",
    "    \n",
    "    # 确保两个 DataFrame 有相同的索引\n",
    "    common_index = center_values.index.intersection(std_values.index)\n",
    "    center_values = center_values.loc[common_index]\n",
    "    std_values = std_values.loc[common_index]\n",
    "    \n",
    "    # 重置索引\n",
    "    center_values = center_values.reset_index()\n",
    "    std_values = std_values.reset_index()\n",
    "    \n",
    "    return center_values, std_values\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d0823f7",
   "metadata": {},
   "source": [
    "## 2. 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d7212a96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "开始分析 Picarro vs Pico 数据...\n",
      "正在加载 Picarro 数据...\n",
      "正在加载 Pico 数据...\n",
      "加载完成: Picarro数据 205043 条, Pico数据 348004 条\n"
     ]
    }
   ],
   "source": [
    "print(\"开始分析 Picarro vs Pico 数据...\")\n",
    "\n",
    "# 设置时间范围\n",
    "start_date = datetime(2025, 11, 13, 0, 0)\n",
    "end_date = datetime(2025, 11, 16, 23, 59)\n",
    "\n",
    "# 时区设置\n",
    "timezone = pytz.timezone('Asia/Shanghai')\n",
    "\n",
    "# 加载数据\n",
    "print(\"正在加载 Picarro 数据...\")\n",
    "picarro_df = load_picarro_data(start_date, end_date, timezone)\n",
    "\n",
    "print(\"正在加载 Pico 数据...\")\n",
    "pico_df = load_pico_data(start_date, end_date, timezone)\n",
    "\n",
    "\n",
    "print(f\"加载完成: Picarro数据 {len(picarro_df)} 条, Pico数据 {len(pico_df)} 条\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9874f73",
   "metadata": {},
   "source": [
    "## 3. 单位统一\n",
    "picarro的H2O单位是%，而pico的H2O单位是ppm，需要将pico的H2O列乘1e4进行缩放。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "68c61195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# picarro_df的H2O列乘1e4\n",
    "picarro_df['H2O'] = picarro_df['H2O'] * 1e4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0120f11",
   "metadata": {},
   "source": [
    "### 4. 定义函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97663572",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_pico_data(picarro_data, pico_data, gas_type):\n",
    "    \"\"\"校正Pico数据，返回校正后的Pico数据\"\"\"\n",
    "    # Align data by merging based on original column names\n",
    "    merged_df = pd.merge(picarro_data[['DATETIME', 'CH4_dry', 'H2O']], \n",
    "                        pico_data[['DATETIME', 'CH4', 'H2O']], \n",
    "                        on='DATETIME', suffixes=('_picarro', '_pico'))\n",
    "    \n",
    "    # Remove NaN values and zero values\n",
    "    merged_df = merged_df.dropna()\n",
    "    \n",
    "    if gas_type == 'CH4':\n",
    "        x_col = 'CH4'      # Pico CH4 column\n",
    "        y_col = 'CH4_dry'  # Picarro CH4 column\n",
    "    else:  # H2O\n",
    "        x_col = 'H2O_pico'     # Pico H2O column\n",
    "        y_col = 'H2O_picarro'  # Picarro H2O column\n",
    "    \n",
    "    # Check if columns exist\n",
    "    if x_col not in merged_df.columns or y_col not in merged_df.columns:\n",
    "        print(f\"警告: 数据中不存在列 {x_col} 或 {y_col}\")\n",
    "        print(f\"可用列: {list(merged_df.columns)}\")\n",
    "        return None\n",
    "    \n",
    "    # Filter out zero values\n",
    "    merged_df = merged_df[(merged_df[x_col] > 0) & (merged_df[y_col] > 0)]\n",
    "    \n",
    "    if merged_df.empty:\n",
    "        print(f\"警告: 没有足够的有效数据用于 {gas_type} 校正\")\n",
    "        return None\n",
    "    \n",
    "    # Prepare data\n",
    "    x_data = merged_df[x_col].values\n",
    "    y_data = merged_df[y_col].values\n",
    "    \n",
    "    # Calculate regression parameters\n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "    \n",
    "    # Apply correction: corrected_pico = slope * original_pico + intercept\n",
    "    corrected_x_data = slope * x_data + intercept\n",
    "    \n",
    "    # Create a copy of the original Pico data and replace the specific column\n",
    "    corrected_pico_data = pico_data.copy()\n",
    "    \n",
    "    # Update the corresponding column in the corrected Pico data\n",
    "    if gas_type == 'CH4':\n",
    "        corrected_pico_data.loc[corrected_pico_data.index.intersection(merged_df.index), 'CH4'] = corrected_x_data\n",
    "    else:  # H2O\n",
    "        corrected_pico_data.loc[corrected_pico_data.index.intersection(merged_df.index), 'H2O'] = corrected_x_data\n",
    "    \n",
    "    return corrected_pico_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "84bd3d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_comparison_plot(picarro_data, pico_data, picarro_std, pico_std, time_window, gas_type, plot_type=\"raw\"):\n",
    "    \"\"\"创建比较散点图，包含误差线\"\"\"\n",
    "    # Step 1: 合并原始数据（重命名列以规范化）\n",
    "    # 重命名 Picarro 和 Pico 列，将 CH4_dry 列重命名为 CH4_picarro，H2O 列重命名为 H2O_picarro\n",
    "    picarro_data_renamed = picarro_data.copy()\n",
    "    picarro_data_renamed = picarro_data_renamed.rename(columns={\n",
    "        'CH4_dry': 'CH4_dry_picarro',\n",
    "        'H2O': 'H2O_picarro'\n",
    "    })\n",
    "    pico_data_renamed = pico_data.copy()\n",
    "    pico_data_renamed = pico_data_renamed.rename(columns={\n",
    "        'CH4': 'CH4_pico',\n",
    "        'H2O': 'H2O_pico'\n",
    "    })\n",
    "    merged_df = pd.merge(picarro_data_renamed[['DATETIME', 'CH4_dry_picarro', 'H2O_picarro']], \n",
    "                        pico_data_renamed[['DATETIME', 'CH4_pico', 'H2O_pico']], \n",
    "                        on='DATETIME', suffixes=('_picarro', '_pico'))\n",
    "    \n",
    "    # Step 2: 合并 Picarro 标准差（需要重命名列以避免冲突）\n",
    "    if not picarro_std.empty:\n",
    "        # 重命名标准差列，使其与原始数据列名对应\n",
    "        picarro_std_renamed = picarro_std.copy()\n",
    "        picarro_std_renamed = picarro_std_renamed.rename(columns={\n",
    "            'CH4_dry': 'CH4_dry_std',\n",
    "            'H2O': 'H2O_std_picarro'\n",
    "        })\n",
    "        merged_df = pd.merge(merged_df, \n",
    "                           picarro_std_renamed[['DATETIME', 'CH4_dry_std', 'H2O_std_picarro']], \n",
    "                           on='DATETIME', how='left')\n",
    "    \n",
    "    # Step 3: 合并 Pico 标准差（需要重命名列以避免冲突）\n",
    "    if not pico_std.empty:\n",
    "        # 重命名标准差列，使其与原始数据列名对应\n",
    "        pico_std_renamed = pico_std.copy()\n",
    "        pico_std_renamed = pico_std_renamed.rename(columns={\n",
    "            'CH4': 'CH4_std_pico',\n",
    "            'H2O': 'H2O_std_pico'\n",
    "        })\n",
    "        merged_df = pd.merge(merged_df, \n",
    "                           pico_std_renamed[['DATETIME', 'CH4_std_pico', 'H2O_std_pico']], \n",
    "                           on='DATETIME', how='left')\n",
    "    \n",
    "    # Remove NaN values and zero values\n",
    "    merged_df = merged_df.dropna()\n",
    "    \n",
    "    if gas_type == 'CH4':\n",
    "        x_col = 'CH4_pico'      # Merged Pico CH4 column (横轴)\n",
    "        y_col = 'CH4_dry_picarro'  # Merged Picarro CH4 column (纵轴)\n",
    "        x_std_col = 'CH4_std_pico'\n",
    "        y_std_col = 'CH4_dry_std'\n",
    "        x_label = 'Pico CH$_4$ (ppm)'\n",
    "        y_label = 'Picarro CH$_4$ (ppm)'\n",
    "    else:  # H2O\n",
    "        x_col = 'H2O_pico'     # Merged Pico H2O column (横轴)\n",
    "        y_col = 'H2O_picarro'  # Merged Picarro H2O column (纵轴)\n",
    "        x_std_col = 'H2O_std_pico'\n",
    "        y_std_col = 'H2O_std_picarro'\n",
    "        x_label = 'Pico H$_2$O (ppm)'\n",
    "        y_label = 'Picarro H$_2$O (ppm)'\n",
    "    \n",
    "    # Check if columns exist\n",
    "    if x_col not in merged_df.columns or y_col not in merged_df.columns:\n",
    "        print(f\"警告: 数据中不存在列 {x_col} 或 {y_col}\")\n",
    "        print(f\"可用列: {list(merged_df.columns)}\")\n",
    "        return\n",
    "    \n",
    "    # Filter out zero values\n",
    "    merged_df = merged_df[(merged_df[x_col] > 0) & (merged_df[y_col] > 0)]\n",
    "    \n",
    "    if merged_df.empty:\n",
    "        print(f\"警告: 没有足够的有效数据用于 {gas_type} 比较\")\n",
    "        return\n",
    "    \n",
    "    # Prepare data\n",
    "    x_data = merged_df[x_col].values\n",
    "    y_data = merged_df[y_col].values\n",
    "    \n",
    "    # Get error data if available\n",
    "    x_errors = merged_df[x_std_col].values if x_std_col and x_std_col in merged_df.columns else None\n",
    "    y_errors = merged_df[y_std_col].values if y_std_col and y_std_col in merged_df.columns else None\n",
    "    \n",
    "    # Calculate R²\n",
    "    if len(x_data) < 2:  # 需要至少2个点才能计算回归\n",
    "        print(f\"警告: {gas_type} 数据点不足，无法进行回归分析\")\n",
    "        return\n",
    "    \n",
    "    slope, intercept, r_value, p_value, std_err = stats.linregress(x_data, y_data)\n",
    "    r_squared = r_value ** 2\n",
    "    \n",
    "    # Calculate additional metrics\n",
    "    differences = y_data - x_data  # Picarro - Pico\n",
    "    me = np.mean(differences)  # Mean Error\n",
    "    rmse = np.sqrt(np.mean(differences**2))  # Root Mean Square Error\n",
    "    relative_error = np.mean(np.abs(differences) / x_data) * 100  # Relative Error (%)\n",
    "    \n",
    "    # Create fitted line\n",
    "    fit_line = slope * x_data + intercept\n",
    "    \n",
    "    # Create scatter plot\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "    \n",
    "    # Set font to Arial\n",
    "    plt.rcParams['font.family'] = 'Arial'\n",
    "    \n",
    "    # Format numbers to 4 significant digits when displaying\n",
    "    x_data_formatted = [float(f\"{val:.4g}\") for val in x_data]\n",
    "    y_data_formatted = [float(f\"{val:.4g}\") for val in y_data]\n",
    "    \n",
    "    # Use the formatted data for plotting\n",
    "    x_data = np.array(x_data_formatted)\n",
    "    y_data = np.array(y_data_formatted)\n",
    "    \n",
    "    # Handle error bars - ensure both x and y errors are arrays of same length as data\n",
    "    if x_errors is not None:\n",
    "        x_errors = np.array(x_errors)\n",
    "        if len(x_errors) != len(x_data):\n",
    "            # If lengths don't match, use the shorter one\n",
    "            min_len = min(len(x_errors), len(x_data))\n",
    "            x_errors = x_errors[:min_len]\n",
    "            x_data = x_data[:min_len]\n",
    "            y_data = y_data[:min_len]\n",
    "            if y_errors is not None:\n",
    "                y_errors = np.array(y_errors)[:min_len]\n",
    "    \n",
    "    if y_errors is not None:\n",
    "        y_errors = np.array(y_errors)\n",
    "        if len(y_errors) != len(y_data):\n",
    "            # If lengths don't match, use the shorter one\n",
    "            min_len = min(len(y_errors), len(y_data))\n",
    "            y_errors = y_errors[:min_len]\n",
    "            x_data = x_data[:min_len]\n",
    "            y_data = y_data[:min_len]\n",
    "            if x_errors is not None:\n",
    "                x_errors = np.array(x_errors)[:min_len]\n",
    "    \n",
    "    # Scatter plot with error bars\n",
    "    if x_errors is not None and y_errors is not None:\n",
    "        ax.errorbar(x_data, y_data, xerr=x_errors, yerr=y_errors, \n",
    "                   fmt='o', alpha=0.6, markersize=5, capsize=3, \n",
    "                   elinewidth=1, markeredgewidth=1, \n",
    "                   label='Data Points with Error Bars')\n",
    "    elif x_errors is not None:\n",
    "        ax.errorbar(x_data, y_data, xerr=x_errors, fmt='o', alpha=0.6, \n",
    "                   markersize=5, capsize=3, elinewidth=1, markeredgewidth=1, \n",
    "                   label='Data Points with X Error Bars')\n",
    "    elif y_errors is not None:\n",
    "        ax.errorbar(x_data, y_data, yerr=y_errors, fmt='o', alpha=0.6, \n",
    "                   markersize=5, capsize=3, elinewidth=1, markeredgewidth=1, \n",
    "                   label='Data Points with Y Error Bars')\n",
    "    else:\n",
    "        ax.scatter(x_data, y_data, alpha=0.6, s=20, label='Data Points')\n",
    "    \n",
    "    # Determine axis limits for square plot\n",
    "    min_val = min(x_data.min(), y_data.min())\n",
    "    max_val = max(x_data.max(), y_data.max())\n",
    "    # Add some padding\n",
    "    padding = (max_val - min_val) * 0.05\n",
    "    min_val -= padding\n",
    "    max_val += padding\n",
    "    \n",
    "    # Make axes square with proper limits\n",
    "    ax.set_xlim(min_val, max_val)\n",
    "    ax.set_ylim(min_val, max_val)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "    \n",
    "    # 1:1 line\n",
    "    ax.plot([min_val, max_val], [min_val, max_val], 'r--', label='1:1 Line', linewidth=2)\n",
    "    \n",
    "    # Fitted line\n",
    "    ax.plot(x_data, fit_line, 'g-', label=f'Fitted Line (y = {slope:.4g}x + {intercept:.4g})', linewidth=2)\n",
    "    \n",
    "    ax.set_xlabel(x_label, fontsize=16)\n",
    "    ax.set_ylabel(y_label, fontsize=16)\n",
    "    plot_type_name = \"Raw\" if plot_type == \"raw\" else \"Corrected\"\n",
    "    ax.set_title(f'{gas_type} Concentration Comparison ({plot_type_name}) (Time Window: {time_window})', fontsize=18)\n",
    "    ax.legend(fontsize=14)\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Add statistics text without background, formatted to 4 significant digits\n",
    "    stats_text = (f'Sample Size: {len(x_data)}\\n'\n",
    "                  f'R$^2$: {r_squared:.4g}\\n'\n",
    "                  f'a: {slope:.4g}\\n'\n",
    "                  f'b: {intercept:.4g}\\n'\n",
    "                  f'ME: {me:.4g}\\n'\n",
    "                  f'RMSE: {rmse:.4g}\\n'\n",
    "                  f'Relative Error: {relative_error:.4g}%')\n",
    "    ax.text(0.05, 0.95, stats_text, transform=ax.transAxes, fontsize=12,\n",
    "            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='white', edgecolor='none', alpha=0.8))\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{gas_type}_comparison_{time_window}_{plot_type}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c51c696",
   "metadata": {},
   "source": [
    "### 5. 主函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "56aabeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "处理时间窗口: 30min\n",
      "重采样后数据点数量 - Picarro: 188, Pico: 193\n",
      "  生成 CH4 原始比较图...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\why\\AppData\\Local\\Temp\\ipykernel_884\\2347313699.py:192: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  校正 Pico CH4 数据...\n",
      "  生成 CH4 校正比较图...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\why\\AppData\\Local\\Temp\\ipykernel_884\\2347313699.py:192: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  生成 H2O 原始比较图...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\why\\AppData\\Local\\Temp\\ipykernel_884\\2347313699.py:192: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  校正 Pico H2O 数据...\n",
      "  生成 H2O 校正比较图...\n",
      "  时间窗口 30min 的分析完成\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\why\\AppData\\Local\\Temp\\ipykernel_884\\2347313699.py:192: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown\n",
      "  plt.show()\n"
     ]
    }
   ],
   "source": [
    "# 时间窗口选项\n",
    "window = '30min'\n",
    "print(f\"\\n处理时间窗口: {window}\")\n",
    "\n",
    "# Resample data with std, filtering points where CV > 10%\n",
    "picarro_resampled, picarro_std = resample_data(picarro_df, window, method='median', max_cv=0.05)\n",
    "pico_resampled, pico_std = resample_data(pico_df, window, method='median', max_cv=0.05)\n",
    "\n",
    "print(f\"重采样后数据点数量 - Picarro: {len(picarro_resampled)}, Pico: {len(pico_resampled)}\")\n",
    "\n",
    "# Generate CH4 raw comparison plot\n",
    "print(f\"  生成 CH4 原始比较图...\")\n",
    "create_comparison_plot(picarro_resampled, pico_resampled, picarro_std, pico_std, window, 'CH4', plot_type=\"raw\")\n",
    "\n",
    "# Correct Pico data for CH4\n",
    "print(f\"  校正 Pico CH4 数据...\")\n",
    "corrected_pico_ch4 = correct_pico_data(picarro_resampled, pico_resampled, 'CH4')\n",
    "if corrected_pico_ch4 is not None:\n",
    "    # Generate CH4 corrected comparison plot\n",
    "    print(f\"  生成 CH4 校正比较图...\")\n",
    "    create_comparison_plot(picarro_resampled, corrected_pico_ch4, picarro_std, pico_std, window, 'CH4', plot_type=\"corrected\")\n",
    "\n",
    "# Generate H2O raw comparison plot\n",
    "print(f\"  生成 H2O 原始比较图...\")\n",
    "create_comparison_plot(picarro_resampled, pico_resampled, picarro_std, pico_std, window, 'H2O', plot_type=\"raw\")\n",
    "\n",
    "# Correct Pico data for H2O\n",
    "print(f\"  校正 Pico H2O 数据...\")\n",
    "corrected_pico_h2o = correct_pico_data(picarro_resampled, pico_resampled, 'H2O')\n",
    "if corrected_pico_h2o is not None:\n",
    "    # Generate H2O corrected comparison plot\n",
    "    print(f\"  生成 H2O 校正比较图...\")\n",
    "    create_comparison_plot(picarro_resampled, corrected_pico_h2o, picarro_std, pico_std, window, 'H2O', plot_type=\"corrected\")\n",
    "\n",
    "print(f\"  时间窗口 {window} 的分析完成\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gdal_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
